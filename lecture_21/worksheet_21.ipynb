{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worksheet 21\n",
    "\n",
    "Name:  \n",
    "UID: \n",
    "\n",
    "### Topics\n",
    "\n",
    "- Logistic Regression\n",
    "\n",
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.datasets as datasets\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "centers = [[0, 0]]\n",
    "t, _ = datasets.make_blobs(n_samples=750, centers=centers, cluster_std=1, random_state=0)\n",
    "\n",
    "# LINE\n",
    "def generate_line_data():\n",
    "    # create some space between the classes\n",
    "    X = np.array(list(filter(lambda x : x[0] - x[1] < -.5 or x[0] - x[1] > .5, t)))\n",
    "    Y = np.array([1 if x[0] - x[1] >= 0 else 0 for x in X])\n",
    "    return X, Y\n",
    "\n",
    "# CIRCLE\n",
    "def generate_circle_data(t):\n",
    "    # create some space between the classes\n",
    "    X = np.array(list(filter(lambda x : (x[0] - centers[0][0])**2 + (x[1] - centers[0][1])**2 < 1 or (x[0] - centers[0][0])**2 + (x[1] - centers[0][1])**2 > 1.5, t)))\n",
    "    Y = np.array([1 if (x[0] - centers[0][0])**2 + (x[1] - centers[0][1])**2 >= 1 else 0 for x in X])\n",
    "    return X, Y\n",
    "\n",
    "# XOR\n",
    "def generate_xor_data():\n",
    "    X = np.array([\n",
    "        [0,0],\n",
    "        [0,1],\n",
    "        [1,0],\n",
    "        [1,1]])\n",
    "    Y = np.array([x[0]^x[1] for x in X])\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Using the above code, generate and plot data that is linearly separable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Fit a logistic regression model to the data a print out the coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression().fit(X, Y)\n",
    "model.coef_\n",
    "model.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Using the coefficients, plot the line through the scatter plot you created in a). (Note: you need to do some math to get the line in the right form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Using the above code, generate and plot the CIRCLE data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Notice that the equation of an ellipse is of the form $$ax^2 + by^2 = c$$\n",
    "\n",
    "Fit a logistic regression model to an appropriate transformation of X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) Plot the decision boundary using the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a mesh to plot in\n",
    "h = .02  # step size in the mesh\n",
    "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "meshData = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "A = model.predict_proba(meshData)[:, 1].reshape(xx.shape)\n",
    "Z = model.predict(meshData).reshape(xx.shape)\n",
    "ax.contourf(xx, yy, A, cmap=\"RdBu\", vmin=0, vmax=1)\n",
    "ax.axis('off')\n",
    "\n",
    "# Plot also the training points\n",
    "ax.scatter(X[:, 0], X[:, 1], c=Y, s=50, alpha=0.9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g) Plot the XOR data. In this 2D space, the data is not linearly separable, but by introducing a new feature $$x_3 = x_1 * x_2$$\n",
    "\n",
    "(called an interaction term) we should be able to find a hyperplane that separates the data in 3D. Plot this new dataset in 3D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "X, Y = generate_xor_data()\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter3D(X[: , 0], X[: , 1], X[: , 0]* X[: , 1], c=Y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h) Apply a logistic regression model using the interaction term. Plot the decision boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(interaction_only=True)\n",
    "lr = LogisticRegression(verbose=0)\n",
    "model = make_pipeline(poly, lr).fit(X, Y)\n",
    "\n",
    "# create a mesh to plot in\n",
    "h = .02  # step size in the mesh\n",
    "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "meshData = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "A = model.predict_proba(meshData)[:, 1].reshape(xx.shape)\n",
    "Z = model.predict(meshData).reshape(xx.shape)\n",
    "ax.contourf(xx, yy, A, cmap=\"RdBu\", vmin=0, vmax=1)\n",
    "ax.axis('off')\n",
    "\n",
    "# Plot also the training points\n",
    "ax.scatter(X[:, 0], X[:, 1], color=Y, s=50, alpha=0.9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "for i in range(20000):\n",
    "    for solver in ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']:\n",
    "        X_transform = PolynomialFeatures(interaction_only=True, include_bias=False).fit_transform(X)\n",
    "        model = LogisticRegression(verbose=0, solver=solver, random_state=i, max_iter=10000)\n",
    "        model.fit(X_transform, Y)\n",
    "        print(model.score(X_transform, Y))\n",
    "        if model.score(X_transform, Y) > .75:\n",
    "            print(\"random state = \", i)\n",
    "            print(\"solver = \", solver)\n",
    "            break\n",
    "\n",
    "print(model.coef_)\n",
    "print(model.intercept_)\n",
    "\n",
    "xx, yy = np.meshgrid([x / 10 for x in range(-1, 11)], [x / 10 for x in range(-1, 11)])\n",
    "z = - model.intercept_ / model.coef_[0][2] - model.coef_[0][0] * xx / model.coef_[0][2] - model.coef_[0][1] * yy / model.coef_[0][2]\n",
    "\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter3D(X[: , 0], X[: , 1], X[: , 0]* X[: , 1], c=Y)\n",
    "ax.plot_surface(xx, yy, z, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i) Using the code below that generates 3 concentric circles, fit a logisitc regression model to it and plot the decision boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t, _ = datasets.make_blobs(n_samples=1500, centers=centers, cluster_std=2,\n",
    "                                random_state=0)\n",
    "\n",
    "# CIRCLES\n",
    "def generate_circles_data(t):\n",
    "    def label(x):\n",
    "        if x[0]**2 + x[1]**2 >= 2 and x[0]**2 + x[1]**2 < 8:\n",
    "            return 1\n",
    "        if x[0]**2 + x[1]**2 >= 8:\n",
    "            return 2\n",
    "        return 0\n",
    "    # create some space between the classes\n",
    "    X = np.array(list(filter(lambda x : (x[0]**2 + x[1]**2 < 1.8 or x[0]**2 + x[1]**2 > 2.2) and (x[0]**2 + x[1]**2 < 7.8 or x[0]**2 + x[1]**2 > 8.2), t)))\n",
    "    Y = np.array([label(x) for x in X])\n",
    "    return X, Y\n",
    "\n",
    "X, Y = ...\n",
    "\n",
    "poly = PolynomialFeatures(2)\n",
    "lr = LogisticRegression(verbose=2)\n",
    "model = make_pipeline(poly, lr).fit(X, Y)\n",
    "\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
